# -*- coding: utf-8 -*-
"""Linear Regression.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ctmdPDbmJfiUEr3ogxHWSzZZM4KrtOTi
"""

# Linear Regression

# The first few lines of code set up the coding environment and loaded the data. As you might be familiar with, you can call on the import function to import any necessary packages.
# You should use conventional aliases as needed. The example below references a dataset on penguins available through the seaborn package.

# Import packages
import pandas as pd
import seaborn as sns

# Load dataset
penguins = sns.load_dataset("penguins")

# Examine first 5 rows of dataset
penguins.head()

# Clean data
# After loading the data, the data was cleaned up to create a subset of data for the purposes of our course. The example isolates just the Chinstrap penguins from the dataset and drops rows with missing data.

# The index of the dataframe is reset using the reset_index()
# function
# . When you subset a dataframe, the original row indices are retained. For example, let’s say there were Adelie or Gentoo penguins in rows 2 and 3.
# By subsetting the data just for Chinstrap penguins, your new dataframe would be listed as row 1 and then row 4, as rows 2 and 3 were removed. By resetting the index of the dataframe,
# the row numbers become rows 1, 2, 3, etc. The data frame becomes easier to work with in the future.

# Review the code below. You are encouraged to run the code in your own notebook.

# Subset just Chinstrap penguins from data set
chinstrap_penguins = penguins[penguins["species"] == "Chinstrap"]
# Reset index of dataframe
chinstrap_penguins.reset_index(inplace = True, drop = True)

# Setup for model construction
# Now that the data is clean, you are able to plot the data and construct a linear regression model. First, extract the one X variable,
# bill_depth_mm, and the one Y variable, flipper_length_mm, that you are targeting.

# Subset Data
ols_data = chinstrap_penguins[["bill_depth_mm", "flipper_length_mm"]]

# Because this example is using statsmodels, save the ordinary least squares formula as a string so the computer can understand how to run the regression.
# The Y variable, flipper_length_mm comes first, followed by a tilde and the name for the X variable, bill_depth_mm.

# Write out formula
ols_formula = "flipper_length_mm ~ bill_depth_mm"

# Construct the model
# In order to construct the model, you’ll first need to import the ols function from the statsmodels.formula.api interface.

# Import ols function
from statsmodels.formula.api import ols

# Next, plug in the formula and the saved data into the ols function. Then, use the fit method to fit the model to the data. Lastly, use the summary method to get the results from the regression model.

# Build OLS, fit model to data
OLS = ols(formula = ols_formula, data = ols_data)
model = OLS.fit()
model.summary()

# Model predictions and residuals
# You can access the predictions and residuals from a fitted
# statsmodels.regression.linear_model.OLS or statsmodels.regression.linear_model.OLSResults object as follows.

# Predictions Use the model’s  predict() method, passing to it an array containing the values of the independent variable(s):

predictions = model.predict(chinstrap_penguins[["bill_depth_mm"]])

# Residuals
# Use the model’s resid attribute:

residuals = model.resid
print(residuals)

"""
Estos son los diferentes parámetros y estadísticas que se muestran en los resultados de la regresión lineal ordinaria (OLS, por sus siglas en inglés) que has proporcionado:

Dep. Variable (Variable Dependiente):

Indica la variable que se está prediciendo o explicando en el modelo de regresión. En este caso, la variable dependiente es "flipper_length_mm", que parece ser la longitud de las aletas de algún tipo de animal.

R-squared (R cuadrado):

El coeficiente de determinación (R cuadrado) indica cuánta variabilidad en la variable dependiente es explicada por el modelo de regresión. En este caso, el R cuadrado es 0.337, lo que significa que aproximadamente el 33.7% de la variabilidad en la longitud de las aletas se explica por el modelo.
Adj. R-squared (R cuadrado ajustado):

Es similar al R cuadrado, pero ajustado por el número de variables independientes en el modelo y el número de observaciones. A menudo se prefiere el R cuadrado ajustado cuando se comparan modelos con un número diferente de variables independientes.

Method (Método):

Indica el método utilizado para ajustar el modelo de regresión. En este caso, se utilizó el método de mínimos cuadrados ordinarios (OLS).

F-statistic (Estadístico F):

Es una medida de la significancia global del modelo de regresión. Evalúa si al menos una de las variables independientes tiene un efecto significativo sobre la variable dependiente. Un valor alto del estadístico F indica que el modelo es estadísticamente significativo.

Prob (F-statistic) (Valor p del estadístico F):

Indica la probabilidad de obtener un estadístico F tan extremo como el observado en el modelo si la verdadera relación entre las variables es nula. Un valor de p bajo (por ejemplo, menos de 0.05) sugiere que el modelo es estadísticamente significativo.

No. Observations (Número de Observaciones):

Es el número de observaciones en el conjunto de datos utilizado para ajustar el modelo de regresión. En este caso, hay 68 observaciones.

Df Residuals (Grados de libertad de residuos):

Es el número de grados de libertad restantes después de ajustar el modelo. En general, es el número de observaciones menos el número de parámetros estimados en el modelo.

Df Model (Grados de libertad del modelo):

Es el número de parámetros estimados en el modelo de regresión, excluyendo el término de intercepción.

Covariance Type (Tipo de Covarianza):

Indica el tipo de estimación de la matriz de covarianza utilizada en el cálculo de los errores estándar y las pruebas de hipótesis. En este caso, se utilizó el tipo de covarianza no robusto.

coef (coeficiente):

Son los coeficientes estimados para cada variable independiente en el modelo de regresión. En este caso, hay un coeficiente para el término de intercepción y otro para la variable independiente "bill_depth_mm".

std err (error estándar):

Es el error estándar de cada coeficiente estimado. Mide la precisión de la estimación del coeficiente.

t (t-value):

Es el valor t asociado con el coeficiente estimado. Mide cuántas desviaciones estándar es el coeficiente estimado de la media poblacional verdadera, bajo la suposición de que el coeficiente es nulo.

P>|t| (valor p):

Es el valor p asociado con el valor t. Indica la probabilidad de obtener un valor t tan extremo como el observado si la verdadera relación entre la variable independiente y la dependiente es nula. Un valor de p bajo sugiere que el coeficiente es significativamente diferente de cero.

[0.025 0.975] (intervalo de confianza del 95%):

Es el intervalo de confianza del 95% para el coeficiente estimado. Indica el rango dentro del cual es probable que se encuentre el coeficiente verdadero con un nivel de confianza del 95%.

Omnibus, Prob(Omnibus), Skew, Kurtosis, Jarque-Bera (JB):

Estadísticas de normalidad y asimetría de los residuos. Se utilizan para evaluar si los residuos del modelo de regresión siguen una distribución normal.
Durbin-Watson:

Estadística de Durbin-Watson, utilizada para detectar autocorrelación en los residuos del modelo de regresión.

AIC (Criterio de Información de Akaike) y BIC (Criterio de Información Bayesiano):

Son medidas de la calidad del ajuste del modelo que penalizan la complejidad del modelo. Valores más bajos indican un mejor ajuste del modelo."""