# -*- coding: utf-8 -*-
"""Multi Regression.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/19-DmrzSLGa_DnbbgC9Ob0GguNymkvLgs
"""

# Import librerías
import pandas as pd
import seaborn as sns

# Import dataset
penguins = sns.load_dataset('penguins')
penguins.head(3)

# Show columns
penguins.columns

# Subset columns and verify for NA's.
penguins = penguins[['body_mass_g','bill_length_mm','sex','species' ]]
penguins.columns
penguins.isna().sum()

# Botar NA's and verify for NA's.
penguins.dropna(inplace=True)
penguins.isna().sum()

# Show 3 first rows of the data.
penguins.head(3)

# Set X and Y variables
penguins_X = penguins[['bill_length_mm','sex','species' ]]
penguins_y = penguins[['body_mass_g']]
print(penguins_X.head(3), '\n') # print(penguins_X.head(3), end='\n\n') otra forma de imprimir con salto de línea.
print(penguins_y.head(3))

# Import train test split
# Se utiliza para dividir un conjunto de datos en conjuntos de entrenamiento y prueba.

from sklearn.model_selection import train_test_split

"""**Implicaciones importantes al elegir:**

**Tamaño del conjunto de entrenamiento y prueba:** Un porcentaje más alto en test_size significa que se asignará una mayor proporción de datos al conjunto de prueba, lo que resultará en un conjunto de entrenamiento más pequeño. Esto puede llevar a un modelo con menos datos para entrenar, lo que podría afectar su capacidad para capturar la complejidad del problema. Por otro lado, un conjunto de prueba más grande puede proporcionar una mejor estimación del rendimiento del modelo en datos no vistos.

**Variabilidad en la evaluación:** La elección del tamaño del conjunto de prueba puede afectar la variabilidad en la evaluación del modelo. Con un conjunto de prueba más pequeño, las estimaciones de rendimiento pueden ser más variables debido a la sensibilidad a la partición específica de los datos. Un conjunto de prueba más grande puede proporcionar estimaciones de rendimiento más estables.

**Riesgo de sobreajuste:** Si el conjunto de entrenamiento es demasiado pequeño en relación con el conjunto de prueba, existe un mayor riesgo de sobreajuste, donde el modelo se ajusta demasiado a los datos de entrenamiento específicos y no generaliza bien a nuevos datos. Esto puede ocurrir especialmente cuando se tienen conjuntos de datos pequeños y modelos complejos.

**Recomendaciones:**

**División equilibrada:** Se recomienda dividir los datos de manera que se mantenga un equilibrio entre el tamaño del conjunto de entrenamiento y el conjunto de prueba. Por ejemplo, una división del 80% para entrenamiento y 20% para prueba es comúnmente utilizada.

**Suficiente tamaño del conjunto de prueba:** El conjunto de prueba debe ser lo suficientemente grande como para proporcionar una evaluación confiable del rendimiento del modelo. Un tamaño del conjunto de prueba del 20-30% del total de datos es comúnmente aceptado, pero puede variar según el tamaño total del conjunto de datos.

**Validación cruzada:** Además de la división en conjunto de entrenamiento y prueba, se recomienda utilizar técnicas de validación cruzada, como la validación cruzada k-fold, para obtener estimaciones más robustas del rendimiento del modelo. Esto implica dividir los datos en k pliegues y entrenar y evaluar el modelo k veces, utilizando diferentes combinaciones de datos de entrenamiento y prueba en cada iteración.

**Consideraciones específicas del problema:** La elección del tamaño del conjunto de prueba también puede depender de las características específicas del problema. Por ejemplo, si los datos están desequilibrados o si hay restricciones en la disponibilidad de datos, es posible que se necesiten tamaños de conjunto de prueba diferentes.
"""

X_train, X_test, y_train, y_test = train_test_split(penguins_X,penguins_y,test_size=0.3, random_state=42)

"""**El patrón de asignación de desempaquetado en Python** es una característica poderosa y elegante del lenguaje que te permite asignar los elementos de una secuencia (como una lista o una tupla) a variables individuales en una sola línea de código. Esto es especialmente útil cuando una función devuelve múltiples valores empaquetados en una secuencia y quieres asignar cada valor a una variable separada.

Ejemplo

Definimos una tupla con varios valores

tupla = (1, 2, 3)

Usamos el patrón de asignación de desempaquetado para asignar cada valor a una variable separada

a, b, c = tupla

Ahora, a contiene el valor 1, b contiene el valor 2, y c contiene el valor 3
"""

# Definimos la formula para el método ols de linear regression
ols_formula = 'body_mass_g ~ bill_length_mm + C(sex) + C(species)' # C tiene que esta en mayúscula.

# Import ols function
from statsmodels.formula.api import ols

# Create de dataframe
ols_data = pd.concat([X_train,y_train], axis = 1)

# Create the OLS formula
OLS = ols(formula=ols_formula, data = ols_data)

# Fit the model to the data
model = OLS.fit()

# Mostrar el resultado
model.summary()

"""**Intercepto (constante):** El intercepto del modelo representa el valor predicho de la variable dependiente cuando todas las variables independientes son iguales a cero. En este caso, el intercepto es de aproximadamente 2032.2111 gramos. Esto significa que, cuando todas las variables independientes son cero, se espera que la masa corporal sea de alrededor de 2032.2111 gramos.

**Coeficiente para sex (Género masculino):** El coeficiente de 528.9508 indica que, manteniendo todas las demás variables constantes, se espera que la masa corporal de un pingüino macho sea mayor en 528.9508 gramos en comparación con un pingüino hembra.

**Coeficiente para species (Especies):**

Para la especie Chinstrap, el coeficiente de -285.3865 indica que, manteniendo todas las demás variables constantes, se espera que la masa corporal de un pingüino Chinstrap sea menor en 285.3865 gramos en comparación con la especie de referencia (probablemente Adelie).


Para la especie Gentoo, el coeficiente de 1081.6246 indica que, manteniendo todas las demás variables constantes, se espera que la masa corporal de un pingüino Gentoo sea mayor en 1081.6246 gramos en comparación con la especie de referencia (probablemente Adelie).


Coeficiente para bill_length_mm (Longitud del pico): El coeficiente de 35.5505 indica que, manteniendo todas las demás variables constantes, por cada aumento de un milímetro en la longitud del pico, se espera que la masa corporal aumente en 35.5505 gramos.

Dep. Variable:
Esta sección indica la variable que estamos tratando de predecir con nuestro modelo de regresión. En este caso, la variable dependiente es "body_mass_g", que representa la masa corporal en gramos de los pingüinos.

R-squared:
Este valor es el coeficiente de determinación, que nos indica la proporción de la variabilidad en la variable dependiente (masa corporal) que es explicada por nuestro modelo. En este caso, el valor de 0.85 significa que aproximadamente el 85% de la variabilidad en la masa corporal se puede explicar por las variables independientes incluidas en el modelo.

Model:
Aquí se muestra el nombre del modelo utilizado, que es OLS (regresión lineal ordinaria). Este es un tipo común de modelo de regresión utilizado para predecir una variable dependiente continua a partir de una o más variables independientes.

Adj. R-squared:
Es similar al R-cuadrado, pero ajustado por el número de variables independientes en el modelo. Proporciona una medida de cuánto mejor se ajusta el modelo en comparación con un modelo con menos variables. En este caso, el valor de 0.847 sugiere que el modelo ajustado es una buena representación de los datos.

Method:
Esta sección indica el método utilizado para estimar el modelo. En este caso, se utilizó el método de Mínimos Cuadrados Ordinarios (OLS), que es un enfoque estándar para ajustar modelos de regresión.

F-statistic:
Esta estadística evalúa la significancia global del modelo. Un valor alto indica que al menos una de las variables independientes es significativa en la predicción de la variable dependiente.

Date:
La fecha en la que se generaron los resultados.

Time:
La hora a la que se generaron los resultados.

No. Observations:
El número total de observaciones en el conjunto de datos utilizado para estimar el modelo.

Df Residuals:
Grados de libertad del error, que es el número de observaciones menos el número de variables en el modelo.

Df Model:
Grados de libertad del modelo, que es el número de variables independientes en el modelo más el intercepto.

Covariance Type:
El tipo de covarianza utilizado en la estimación del modelo. En este caso, se utilizó una covarianza no robusta.

coef:
Los coeficientes estimados para cada variable en el modelo. Estos coeficientes indican cómo cambia la variable dependiente por cada unidad de cambio en la variable independiente correspondiente.

std err:
El error estándar de los coeficientes estimados. Proporciona una medida de la precisión de las estimaciones de los coeficientes.

t:
La estadística t, que evalúa la significancia individual de cada coeficiente.

P>|t|:
El valor p asociado a la prueba t. Indica la probabilidad de observar el coeficiente estimado si la verdadera diferencia entre la variable independiente y la dependiente es cero.

[0.025, 0.975]:
Los intervalos de confianza del 95% para los coeficientes estimados. Indican el rango dentro del cual podemos estar 95% seguros de que el verdadero valor del coeficiente cae.

Omnibus, Prob(Omnibus):
Prueba de Omnibus de normalidad de los residuos y su valor p asociado. Evalúa si los residuos del modelo se distribuyen normalmente.

Durbin-Watson:
La estadística de Durbin-Watson, que prueba la autocorrelación de los residuos. Proporciona información sobre si hay patrones de correlación serial en los residuos del modelo.

Jarque-Bera (JB), Prob(JB):
Prueba de Jarque-Bera de normalidad de los residuos y su valor p asociado. Es otra prueba de normalidad de los residuos del modelo.

Skew:
La asimetría de los residuos. Indica si los residuos están distribuidos simétricamente alrededor de cero.

Kurtosis:
La curtosis de los residuos. Proporciona información sobre la forma de la distribución de los residuos en comparación con una distribución normal.

Cond. No.:
Número de condición, que mide la multicolinealidad en el modelo. Valores altos indican una fuerte multicolinealidad entre las variables independientes.

Notes:
Notas adicionales sobre los resultados, como supuestos sobre la distribución de los residuos o cualquier otra información relevante para la interpretación del modelo.
"""