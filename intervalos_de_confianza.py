# -*- coding: utf-8 -*-
"""Intervalos de Confianza.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1DNlikcUZ7w-4hbvtGgEPzJGH9-VFMMKT

# **Crear intervalos de confianza.**

**Utilizando la distribución t de Student.**
"""

import numpy as np
from scipy import stats
import matplotlib.pyplot as plt

# Datos de ejemplo para MoSold
ventas = np.array([23, 25, 27, 28, 29, 31, 32, 33, 34, 35])

# Histograma
plt.hist(ventas, bins=5, edgecolor='black')
plt.title('Histograma de datos')
plt.xlabel('Valor')
plt.ylabel('Frecuencia')
plt.show()

# Prueba de normalidad Shapiro-Wilk
shapiro_stat, shapiro_p_value = stats.shapiro(ventas)
print('Prueba de normalidad Shapiro-Wilk:')
print('Estadístico:', shapiro_stat)
print('Valor p:', shapiro_p_value)


# Calculamos la media de MoSold
ventas_mean = ventas.mean()
print('Media Ventas:')
print(ventas_mean)

# Calculamos el error estándar de la media
estimated_error = ventas.std() / np.sqrt(len(ventas))

# Construimos el intervalo de confianza utilizando la distribución normal
intervalo_confianza = stats.norm.interval(0.95, loc=ventas_mean, scale=estimated_error)
print('El intervalo de confianza al 95% para la variable MoSold es:')
print(intervalo_confianza)

"""En esta prueba, la hipótesis nula (H0) es que los datos siguen una distribución normal. Si el valor p asociado con la prueba es menor que un umbral predeterminado (comúnmente 0.05), entonces rechazamos la hipótesis nula y concluimos que los datos no siguen una distribución normal.

En tu caso, el estadístico de la prueba de Shapiro-Wilk es 0.9637 y el valor p es 0.8280. Dado que el valor p es mayor que el umbral comúnmente utilizado de 0.05, no tenemos suficiente evidencia para rechazar la hipótesis nula. Por lo tanto, basado en esta prueba, no hay suficiente evidencia para concluir que los datos no siguen una distribución normal.

Exactamente, en muchos casos un enfoque básico como calcular el intervalo de confianza para la media utilizando la distribución normal es suficiente y proporciona una estimación razonable de la incertidumbre asociada con la estimación de la media.

Sin embargo, si deseas realizar pronósticos más avanzados y tener en cuenta la tendencia, la estacionalidad u otros patrones en tus datos, entonces podrías considerar técnicas más sofisticadas como el suavizado exponencial simple o modelos de series temporales.

**Utilizando la distribución normal estándar (z)**
"""

import numpy as np
from scipy import stats

# Datos de ejemplo para MoSold
sampled_data = np.array([23, 25, 27, 28, 29, 31, 32, 33, 34, 35])

# Calculamos la media de MoSold
sampled_mean = sampled_data.mean()

# Calculamos el error estándar de la media
estimated_error = sampled_data.std() / np.sqrt(len(sampled_data))

# Construimos el intervalo de confianza utilizando la distribución normal estándar (z)
intervalo_confianza_z = stats.norm.interval(0.95, loc=sampled_mean, scale=estimated_error)
print('El intervalo de confianza al 95% para la variable MoSold utilizando la distribución normal estándar (z) es:')
print(intervalo_confianza_z)

"""# **2. Verificar la regla empírica.**"""

from google.colab import drive
drive.mount('/content/drive')

# Montando el drive para acceder a los archivos, ya que tengo los csv en mi Drive, esto no es necesario si ustedes tienen el archivo en su escritorio.

import pandas as pd
# Ruta del archivo CSV en Google Drive.
productos_csv = '/content/drive/My Drive/Colab Notebooks/Módulo 4/house.csv'

# Importando la data y transformandola a objeto Dataframe.
# En este poner el path correspondiente del archivo como parametro de pd.read_csv.
df_house = pd.read_csv(productos_csv)

variables_a_eliminar = ['Alley','FireplaceQu','PoolQC', 'Fence', 'MiscFeature', 'LotFrontage']

df_house_limpia = df_house.drop(variables_a_eliminar, axis=1)

df_house_limpia.describe()

# Lo primero para es graficar los datos mediante un histograma para identificar que variables pueden sugerir
# una distribución normal.

# Supongamos que df_house_limpia es tu DataFrame y contiene las columnas para los histogramas
fig, axes = plt.subplots(figsize=(12, 12))
df_house_limpia.hist(ax=axes)

# Ajusta la disposición manualmente
plt.subplots_adjust(hspace=0.8, wspace=0.8)  # Ajusta el espacio horizontal y vertical entre los subgráficos

# Muestra la figura
plt.show()

# Python muestra un mensaje de advertencia que dice que los subgráficos se superponen ligeramente debido a la configuración actual,
# pero como los gráficos se muestran correctamente y no hay ningún problema aparente, se continua sin problemas.

"""Según los histogramas podemos ver que algunas variables parecen seguir una distribución normal estas son:

MoSold
TotRmsAbvGrd
GarageArea
OverallQual
GrLivArea
2ndFlrSF
1stFlrSF
SalePrice
Por esta razón, vamos a realizar un remuestreo eligiendo la variable:

'MoSold' que representa el mes en que se vendió una casa.
Con la finalidad de identificar si sigue una distribución normal, pero de una forma técnica.
"""

# Remuestreo para calcular si la variable MoSold presenta una distribución normal.

MoSold = df_house_limpia['MoSold']
MoSold.hist(figsize=(12, 12))
plt.show()

# Resumen estadístico de la variable MoSold.
MoSold.describe()

"""El histrograma parece mostrar una distribución normal dado que tiene una forma de campana, una media localizada en el centro de la curva con valor 6.32 y los costados simetrica a la media, pero aún no podemos dar por hecho que sea de este modo, por ello necesitamos realizar este procedimiento de una forma más técnica.

Para saber con exactitud si esta variable sigue una distribución normal es necesario evaluar bajo la regla empírica, la cual nos dice que:

Aproximadamente el 68% de los datos se encuentran dentro de una desviación estándar de la media.
Aproximadamente el 95% de los datos se encuentran dentro de dos desviaciones estándar de la media.
Aproximadamente el 99.7% de los datos se encuentran dentro de tres desviaciones estándar de la media.
"""

# Vamos a importar librerías que nos permitiran definir si esta variable sigue una distribución normal o no.

from scipy import stats
import statsmodels.api as sm

# Ahora vamos realizar los calculos necesarios para verificar la regla empírica.

# Necesitamos la Media y la Desviación Estándar.

# Calculo Media.
media_MoSold = MoSold.mean()
print(f'Media: {media_MoSold}')

# Calculo Desviación Estándar.
std_MoSold = MoSold.std()
print(f'Desviación estándar: {std_MoSold}')

"""Ahora para comprobar la regla empírica necesitamos calcular los intervalos de desviación estándar:

68% de los valores:

Media + 1 x desviación estándar: Aproximadamente el 68% de los datos se encuentran dentro de una desviación estándar de la media.

95% de los valores:

Media + 2 x desviación estándar: Aproximadamente el 95% de los datos se encuentran dentro de dos desviaciones estándar de la media.

99.7% de los valores:

Media + 3 x desviación estándar: Aproximadamente el 99.7% de los datos se encuentran dentro de tres desviaciones estándar de la media.
"""

# Sabiendo que la media es el punto medio de un rango de datos, podemos entender que
# existen datos sobre y por debajo de la media por ello vamos a calcular los limites
# superior +1 e inferiores -1 luego aplicaremos la fórmula anteriormente vista y
# verificaremos si sigue la regla empírica o no.

limite_superior = media_MoSold + 1 * std_MoSold
limite_inferior = media_MoSold - 1 * std_MoSold

((MoSold >= limite_inferior) & (MoSold <= limite_superior)).mean()*100

"""Podemos comprobar que el 69.65% de los valores caen dentro de una desviación estándar."""

# Mismo procedimiento pero para 2 desviaciones estándar.

limite_superior = media_MoSold + 2 * std_MoSold
limite_inferior = media_MoSold - 2 * std_MoSold

((MoSold >= limite_inferior) & (MoSold <= limite_superior)).mean()*100

"""Podemos comprobar que el 95.96% de los valores caen dentro de una desviación estándar."""

# Mismo procedimiento pero para 3 desviaciones estándar.

limite_superior = media_MoSold + 3 * std_MoSold
limite_inferior = media_MoSold - 3 * std_MoSold

((MoSold >= limite_inferior) & (MoSold <= limite_superior)).mean()*100

"""Podemos comprobar que el 100% de los valores caen dentro de una desviación estándar.

Ahora siguiendo la regla empírica tenemos que:

Media + 1 x desviación estándar:

Regla empírica: 68%
Variable MoSold: 69.66%

Media + 2 x desviación estándar:

Regla empírica: 95%
Variable MoSold: 95.96%

Media + 3 x desviación estándar:

Regla empírica: 99.7%
Variable MoSold: 100.00%

En este punto es seguro decir que esta variable sigue una distribución normal, dado que hemos obtenido valores que siguen la regla empírica, obviamente no se espera que sean los mismos porcentajes, pero es claro que es acorde a este método.

# **3. Casos de transformación.**

**En caso de que los datos no sigan una distribución normal.**
"""

# Aplicar transformación logarítmica
ventas_log = np.log(ventas)

# Mostrar los datos transformados
print("Datos originales:", ventas)
print("Datos transformados (logarítmicos):", ventas_log)

# Prueba de normalidad Shapiro-Wilk
shapiro_stat, shapiro_p_value = stats.shapiro(ventas_log)
print('Prueba de normalidad Shapiro-Wilk:')
print('Estadístico:', shapiro_stat)
print('Valor p:', shapiro_p_value)

import numpy as np
import matplotlib.pyplot as plt
from scipy import stats

# Datos de ejemplo para ventas
ventas = np.array([23, 25, 27, 28, 29, 31, 32, 33, 34, 35])

# Aplicar transformación Box-Cox
ventas_boxcox, lambda_value = stats.boxcox(ventas)

# Histograma de los datos transformados
plt.hist(ventas_boxcox, bins=5, edgecolor='black')
plt.title('Histograma de Ventas (Transformación Box-Cox)')
plt.xlabel('Ventas (Transformación Box-Cox)')
plt.ylabel('Frecuencia')
plt.show()

# Gráfico Q-Q de los datos transformados
stats.probplot(ventas_boxcox, dist="norm", plot=plt)
plt.title('Gráfico Q-Q de Ventas (Transformación Box-Cox)')
plt.xlabel('Cuantiles teóricos')
plt.ylabel('Cuantiles observados')
plt.show()

# Imprimir el valor de lambda
print("Valor de lambda en la transformación Box-Cox:", lambda_value)